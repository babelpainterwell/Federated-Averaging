<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Federated Averaging</title>
    <meta property="og:title" content="Federated Averaging" />
    <meta name="twitter:title" content="Federated Averaging" />
    <meta
      name="description"
      content="Your project about your cool topic described right here."
    />
    <meta
      property="og:description"
      content="Your project about your cool topic described right here."
    />
    <meta
      name="twitter:description"
      content="Your project about your cool topic described right here."
    />
    <meta property="og:type" content="website" />
    <meta name="twitter:card" content="summary" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <!-- bootstrap for mobile-friendly layout -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"
      integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N"
      crossorigin="anonymous"
    />
    <script
      src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js"
      integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct"
      crossorigin="anonymous"
    ></script>
    <link
      href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700"
      rel="stylesheet"
    />
    <link href="style.css" rel="stylesheet" />
    <style>
      .center-image {
        display: flex;
        justify-content: center;
        align-items: center;
      }
    </style>
  </head>
  <body class="nd-docs">
    <div class="nd-pageheader">
      <div class="container">
        <h1 class="lead">
          <nobr class="widenobr">Federated Averaging</nobr>
          <nobr class="widenobr">For CS 7150</nobr>
        </h1>
      </div>
    </div>
    <!-- end nd-pageheader -->

    <div class="container">
      <div class="row">
        <div class="col justify-content-center text-center">
          <h2>
            An Analysis of [Communication-Efficient Learning of Deep Networks
            from Decentralized Data]
          </h2>
          <p style="text-align: left">
            Federated learning has gained widespread use in healthcare sectors
            where data sharing is often challenging due to concerns over user
            privacy and data ownership. Without adequate techniques to utilize
            these "isolated" data, we typically encounter data silos. Hospitals
            are eager to leverage their data but lack the knowledge to do so
            effectively. Introduced by Google in 2016, federated learning was
            designed to tackle this issue by adhering to the core principle that
            only model gradients or weights, not raw data, are exchanged among
            servers.
          </p>
          <p style="text-align: left">
            Yet, in recent years, we haven’t seen this technology adopted on a
            large scale, despite increasing societal concern for data privacy
            from both regulatory agencies and the public. One possible reason is
            that tech companies may lack the incentive to allow users to keep
            their data on local devices, as this data is a lucrative resource
            for them. However, we are interested in investigating, from a
            technical standpoint, what factors are impeding the broader adoption
            of this technology.
          </p>
          <img src="FL1.png" alt="Federated Learning" style="width: 100%" />
          <p style="text-align: left">
            The paper "Communication-Efficient Learning of Deep Networks from
            Decentralized Data" is seminal in introducing federated learning. It
            outlines the fundamental architecture of an FL system and an
            aggregation algorithm for updating the model on a central server.
            Although this work primarily focuses on optimization properties
            within an FL setting and offers limited discussion on practical
            issues that might arise in real-world applications, we believe it
            provides an excellent foundation for understanding the technology
            and setting the stage for future research or practical applications.
            By the end of this project, we aim to implement this technique
            hands-on and uncover insights into potential solutions for several
            practical challenges.
          </p>
        </div>
      </div>
      <div class="row">
        <div class="col">
          <h2>
            Literature Review; Biography; Social Impact; Industry Applications;
            Follow-on Research; and Peer-Review
          </h2>
          <h2>1. Literature Review</h2>
          <p>
            The concept of federated learning introduced in this paper builds
            upon various prior works in distributed computing,
            privacy-preserving data analysis, and machine learning. Before this
            paper, most machine learning models relied on centralized data
            collection, which raised concerns about data privacy and efficiency.
            The paper references earlier works on parallelized learning and data
            decentralization but takes a novel approach by focusing on
            communication efficiency and privacy.
          </p>
          <h3>The FedAvg Algorithm - Overview</h3>
          <p>
            The FedAvg algorithm is designed to efficiently train a global model
            in a federated setting. The key steps are as follows:
          </p>
          <ul>
            <li>
              <b>Initialization:</b> A global model is initialized on a central
              server.
            </li>
            <li>
              Local Training: This global model is sent to a subset of
              participating devices (clients). Each client trains the model on
              their local data.
            </li>
            <li>
              <b>Model Updating:</b> After local training, each client sends
              their model updates (i.e., the weights of the trained model) back
              to the server. Notably, the actual data remains on the client,
              ensuring privacy.
            </li>
            <li>
              <b>Aggregation:</b> The server aggregates these updates, typically
              by averaging the weights, to update the global model.
            </li>
            <li>
              <b>Iteration:</b> Steps 2-4 are repeated for several rounds until
              the model converges or meets certain performance criteria.
            </li>
          </ul>

          <p></p>
          <h2>2. Biograpphy</h2>
          <ol>
            <li>
              <strong>Brendan McMahan</strong>
              <ul>
                <li>
                  <strong>Research Field:</strong> Brendan McMahan's research
                  primarily focuses on machine learning, with a specific
                  interest in federated learning, privacy-preserving AI, and
                  distributed algorithms.
                </li>
                <li>
                  <strong>Experience:</strong> McMahan is known for his work at
                  Google, where he has been a key figure in the development of
                  federated learning technologies. His contributions have been
                  instrumental in advancing machine learning techniques that are
                  both privacy-conscious and efficient for use on decentralized
                  data.
                </li>
              </ul>
              <div class="center-image">
                <img src="Brendan.jpeg" alt="Brendan" style="width: 20%" />
              </div>
            </li>
            <li>
              <strong>Eider Moore</strong>
              <ul>
                <li>
                  <strong>Research Field:</strong> Eider Moore's research
                  interests are less publicly documented, but their contribution
                  to this paper suggests a focus on distributed machine learning
                  and privacy-preserving technologies.
                </li>
              </ul>
            </li>
            <li>
              <strong>Daniel Ramage</strong>
              <ul>
                <li>
                  <strong>Research Field:</strong> Daniel Ramage specializes in
                  natural language processing (NLP) and machine learning, with a
                  particular interest in applying these technologies in
                  practical, user-centered contexts.
                </li>
                <li>
                  <strong>Experience:</strong> Ramage has a strong background in
                  both academia and industry. He has worked on various NLP and
                  machine learning projects, contributing to the development of
                  technologies that bridge the gap between theoretical research
                  and real-world applications.
                </li>
              </ul>
            </li>
            <li>
              <strong>Seth Hampson</strong>
              <ul>
                <li>
                  <strong>Research Field:</strong> Seth Hampson's specific
                  research interests are not widely publicized. However, his
                  involvement in this paper indicates a focus on distributed
                  systems and machine learning.
                </li>
              </ul>
            </li>
            <li>
              <strong>Blaise Agüera y Arcas</strong>
              <ul>
                <li>
                  <strong>Research Field:</strong> Blaise Agüera y Arcas works
                  primarily in machine learning, with a strong interest in
                  neural networks, computational neuroscience, and
                  human-computer interaction.
                </li>
                <li>
                  <strong>Experience:</strong> Agüera y Arcas is known for his
                  work at Google, particularly in AI and machine learning. He
                  has played a significant role in developing innovative
                  technologies and has been a prominent speaker on topics
                  related to AI and the intersection of technology and society.
                </li>
              </ul>
            </li>
          </ol>

          <h2>3. Social Impact</h2>
          <p>The social implications of this research are significant</p>

          <div class="center-image">
            <img src="FL4.jpeg" alt="Federated Learning" style="width: 30%" />
          </div>
          <ul>
            <li>
              <b>Privacy Preservation:</b> By enabling machine learning models
              to be trained on-device without the need to share personal data,
              this approach addresses major privacy concerns.
            </li>
            <li>
              <b>Accessibility and Equity:</b> Federated learning allows for
              model training on a wide variety of devices, including those with
              limited computational resources, promoting more equitable access
              to AI technology.
            </li>
            <li>
              <b>Data Security: </b> Reducing the need to centralize data for
              training models lowers the risk of data breaches.
            </li>
          </ul>
          <h2>4. Industry Applications</h2>
          <p>
            Federated learning is particularly relevant in scenarios where
            individual entities must train models on datasets larger than their
            own but are unable to share the raw data due to legal, strategic, or
            economic considerations. The success of this technology hinges on
            robust connections between local servers and the minimal
            computational power required for each node.
          </p>

          <p>
            In the realm of transportation, self-driving cars leverage various
            machine learning technologies such as computer vision for obstacle
            analysis and machine learning for adapting to environmental factors,
            like the condition of the road. The traditional cloud-based approach
            for managing a potentially large fleet of self-driving cars poses
            safety risks due to the need for rapid real-world responses.
            Federated learning emerges as a solution by reducing data transfer
            volumes and expediting the learning processes.
          </p>

          <p>
            Within the context of industry and smart manufacturing, machine
            learning techniques are widely adopted to enhance industrial
            processes' efficiency and effectiveness while maintaining a high
            level of safety. Despite these advancements, the privacy of
            sensitive data remains a paramount concern for industries. Federated
            learning algorithms offer a viable solution by addressing these
            issues without compromising sensitive information. Additionally,
            federated learning finds applications in PM2.5 prediction,
            supporting smart city sensing applications.
          </p>

          <p>
            Regarding medicine and digital health, federated learning tackles
            challenges related to data governance and privacy by facilitating
            collaborative algorithm training without the need for direct data
            exchange. The conventional approach of centralizing data from
            various medical institutions raises critical concerns about patient
            privacy and data protection. Federated learning enables the training
            of machine learning models at scale, across multiple medical
            institutions while preserving data integrity. Notably, recent
            research validates the effectiveness of federated learning in
            predicting clinical outcomes for patients with COVID-19,
            demonstrating accuracy and generalizability in a global context. A
            systematic review of federated learning in healthcare outlines
            challenges specific to medical data, emphasizing the need for
            careful consideration.
          </p>

          <p>
            A collaborative effort between industry and academia has yielded
            MedPerf, an open-source platform designed to validate medical AI
            models using real-world data. It relies on federated evaluation of
            AI models to address patient privacy concerns and utilizes diverse
            benchmark committees to define specifications for neutral,
            clinically impactful benchmarks.
          </p>

          <p>
            In the field of robotics, which spans a spectrum from simple,
            repetitive tasks to complex, unpredictable activities, machine
            learning is indispensable. Federated learning stands out as a
            solution to enhance conventional machine learning training methods.
            Research papers showcase the application of federated learning in
            diverse robotic scenarios, including navigation over various
            environments, multi-robot navigation under limited communication
            bandwidth, and vision-based navigation, all contributing to improved
            sim-to-real transfer.
          </p>

          <h2>5. Follow-on Research</h2>
          <p>
            In the paper "Communication-Efficient Learning of Deep Networks from
            Decentralized Data," several potential issues are identified that
            can hinder the effective implementation of federated learning:
          </p>

          <ol>
            <li>
              <strong>Non-IID Data Distribution:</strong> Data in federated
              learning is typically not identically and independently
              distributed (non-IID) across the network. This variability can
              negatively impact the learning process and the performance of the
              global model.
            </li>
            <li>
              <strong>Unbalanced Data:</strong> The amount of data across
              devices can be highly unbalanced, leading to skewed model updates
              and potentially reducing the overall effectiveness of the model.
            </li>
            <li>
              <strong>Limited Communication Bandwidth:</strong> Federated
              learning is challenged by limited bandwidth for communication
              between the devices and the central server, which can hinder the
              process, especially when dealing with large models or many
              devices.
            </li>
            <li>
              <strong>Devices Heterogeneity:</strong> There is significant
              heterogeneity in the computational capabilities, storage, and
              network connectivity of the devices in federated learning, causing
              challenges in synchronizing and executing the learning process
              efficiently.
            </li>
          </ol>
          <h2>6. Peer-Review</h2>
          <p>
            The paper "Communication-Efficient Learning of Deep Networks from
            Decentralized Data" is a seminal work in the field of federated
            learning. It outlines the fundamental architecture of an FL system
            and an aggregation algorithm for updating the model on a central
            server. Although this work primarily focuses on optimization
            properties within an FL setting and offers limited discussion on
            practical issues that might arise in real-world applications, we
            believe it provides an excellent foundation for understanding the
            technology and setting the stage for future research or practical
            applications.
          </p>
          <h2>7. Code Implementation</h2>
          <div style="display: flex; justify-content: space-between">
            <img
              src="FL2.png"
              alt="Federated Learning"
              style="width: 30%; margin-right: 5%"
            />
            <img
              src="server.png"
              alt="Server"
              style="width: 30%; margin-right: 5%"
            />
            <img src="client.png" alt="Client" style="width: 30%" />
          </div>
          <br
          <p>
            <a
              href="https://colab.research.google.com/drive/1LIyYtxJQ5UTt9A95EvAfDNyz_blUF9X5?usp=sharing#scrollTo=egkDpRSiPyWY"
              >Explore our Federated Learning Colab Notebook</a
            >
          </p>

          <h2>Conclusion</h2>
          <p>
            The FedAvg algorithm is a cornerstone in federated learning,
            addressing both the efficiency of model training in decentralized
            environments and the privacy concerns associated with data sharing.
            Its design and implementation have opened up new possibilities in
            the application of machine learning models, especially in scenarios
            where data privacy and communication efficiency are paramount.
          </p>

          <h3>References</h3>

          <p>
            <a name="reference-1">[i]</a>
            <a href="https://arxiv.org/abs/1912.04977v3">arXiv:1912.04977v3.</a>
          </p>
          <p>
            <a name="reference-2">[ii]</a>
            <a href="https://dl.acm.org/doi/10.1145/3414045.3415949"
              >https://dl.acm.org/doi/10.1145/3414045.3415949.</a
            >
          </p>
          <p>
            <a name="reference-3">[iii]</a>
            <a href="https://www.mdpi.com/1424-8220/21/13/4586"
              >https://www.mdpi.com/1424-8220/21/13/4586.</a
            >
          </p>
          <p>
            <a name="reference-4">[iv]</a>
            <a href="https://doi.org/10.1038/s41591-021-01506-3"
              >https://doi.org/10.1038/s41591-021-01506-3.</a
            >
          </p>
          <p>
            <a name="reference-5">[v]</a>
            <a href="https://www.mdpi.com/2076-3417/11/23/11191"
              >https://www.mdpi.com/2076-3417/11/23/11191.</a
            >
          </p>
          <p>
            <a name="reference-6">[vi]</a>
            <a
              href="https://mlcommons.org/2023/07/announcing-medperf-open-benchmarking-platform-for-medical-ai/"
              >https://mlcommons.org/2023/07/announcing-medperf-open-benchmarking-platform-for-medical-ai/.</a
            >
          </p>
          <p>
            <a name="reference-7">[vii]</a>
            <a href="https://arxiv.org/abs/1901.06455"
              >https://arxiv.org/abs/1901.06455.</a
            >
          </p>
          <p>
            <a name="reference-8">[viii]</a>
            <a href="https://arxiv.org/abs/2202.01141"
              >https://arxiv.org/abs/2202.01141.</a
            >
          </p>

          <h2>Team Members</h2>

          <p>Gabriel Cuchacovich</p>
          <p>Zhongwei Zhang</p>
        </div>
        <!--col-->
      </div>
      <!--row -->
    </div>
    <!-- container -->

    <footer class="nd-pagefooter">
      <div class="row">
        <div class="col-6 col-md text-center">
          <a href="https://cs7150.baulab.info/">About CS 7150</a>
        </div>
      </div>
    </footer>
  </body>
  <script>
    $(document).on("click", ".clickselect", function (ev) {
      var range = document.createRange();
      range.selectNodeContents(this);
      var sel = window.getSelection();
      sel.removeAllRanges();
      sel.addRange(range);
    });
    // Google analytics below.
    window.dataLayer = window.dataLayer || [];
  </script>
</html>
